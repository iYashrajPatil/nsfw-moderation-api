# ğŸ›¡ï¸ Multi-Modal NSFW Content Moderation API  
*(Image Â· Text Â· Video | Lightweight Â· Open-Source Â· CPU-Only)*

A **production-ready, multi-modal content moderation system** designed for **social media platforms**.  
It classifies **images, text, and videos** into **SAFE**, **REVIEW**, or **NSFW** using **lightweight open-source models**, rule-based logic, and confidence scoring.

This project focuses on **practical, deployable content moderation**, not just raw machine-learning output.

---

## ğŸ“Œ Problem Statement

Platforms handling user-generated content (social media, forums, marketplaces, short-video apps) must automatically detect **explicit, abusive, or inappropriate content** to ensure safety, compliance, and user trust.

Pure ML-only moderation systems often suffer from:

- âŒ High false positives (beach, gym, medical, sports content)
- âŒ Poor explainability
- âŒ Expensive GPU requirements
- âŒ Difficult deployment & scaling
- âŒ No clear escalation strategy for ambiguous content

---

## ğŸ’¡ Solution Overview

This system implements a **multi-layered moderation pipeline** that combines:

- âœ… **Image Moderation** â†’ NudeNet + rule-based scoring  
- âœ… **Text Moderation** â†’ TF-IDF + Logistic Regression + keyword rules  
- âœ… **Video Moderation** â†’ Frame sampling + image moderation reuse  
- âœ… **Central Orchestration** â†’ Unified verdicts & confidence scoring  
- âœ… **Production Logging** â†’ Auditable moderation decisions  

Each input is classified into:

SAFE | REVIEW | NSFW


with a **confidence score (0.0 â€“ 1.0)**.

---

## ğŸ§  System Architecture

                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   FastAPI Server     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Moderation Engine   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                        â”‚       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”   â–¼
        â”‚ Image Moderator    â”‚  Text Moderator
        â”‚ (NudeNet + Rules)  â”‚  (TF-IDF + Rules)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                        â–¼
                Video Moderator
           (Frame Sampling + Image Moderator)


- **Single verdict format**
- **Modular & extensible**
- **CPU-only inference**
- **No paid APIs**
- **Offline / self-hosted**

---

## ğŸ§ª Moderation Logic

### ğŸ–¼ï¸ Image Moderation
- Uses **NudeNet (ONNX, CPU-only)**
- Detects explicit & suggestive body parts
- Applies **rule-based aggregation** to reduce false positives
- Verdicts based on configurable thresholds

### âœï¸ Text Moderation
- Hybrid approach:
  - TF-IDF + Logistic Regression (trained on public datasets)
  - Keyword-based rule scoring
- Designed for:
  - Sexual content
  - Abusive language
  - Toxic comments
- Conservative aggregation â†’ **REVIEW instead of over-blocking**

### ğŸï¸ Video Moderation
- No heavy video neural networks
- Uses **frame sampling (1 frame every 2 seconds)**
- Reuses **existing image moderator**
- Aggregates frame-level decisions
- Early-exit optimization for obvious NSFW content

---

## ğŸ“¤ Output Format (Consistent Across Modalities)

```json
{
  "type": "image | text | video",
  "verdict": "SAFE | REVIEW | NSFW",
  "confidence": 0.0
}
```
## ğŸš€ Getting Started
1ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

2ï¸âƒ£ Run the API

python -m uvicorn App.main:app --reload

3ï¸âƒ£ Test via Swagger UI

http://127.0.0.1:8000/docs

NSFW_MODERATION/
â”‚
â”œâ”€â”€ App/
â”‚   â”œâ”€â”€ classifier.py              # Image moderation (NudeNet)
â”‚   â”œâ”€â”€ text_moderator/             # Text moderation module
â”‚   â”œâ”€â”€ video_moderator/            # Video moderation module
â”‚   â”œâ”€â”€ moderation_engine.py        # Central orchestrator
â”‚   â”œâ”€â”€ logger.py                   # Central logging config
â”‚   â”œâ”€â”€ main.py                     # FastAPI app
â”‚   â”œâ”€â”€ models/                     # Trained ML models
â”‚   â”œâ”€â”€ tmp_uploads/                # Temporary files (gitignored)
â”‚   â””â”€â”€ logs/
â”‚       â””â”€â”€ moderation.log          # Moderation logs
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

## ğŸ“Š Logging & Observability

All moderation decisions are logged with:

- Input type
- Verdict
- Confidence
- Error details (if any)

This enables:

- Auditing moderation behavior
- Debugging false positives
- Compliance reporting
- Production monitoring

## âš ï¸ Limitations (Honest Disclosure)

- Very short explicit flashes in videos may be missed
- Sarcasm & deep context in text may require human review
- Designed for social media moderation, not adult platforms
###### These are intentional trade-offs for speed, cost, and deployability.

## ğŸ§‘â€ğŸ’» Ideal Use Cases

- Social media platforms
- Content upload moderation
- Reels / Shorts / Stories filtering
- Marketplace image safety checks
- Academic & internship projects
- Open-source moderation research

## ğŸ“œ License

- This project uses only free & open-source components and is intended for ethical, public-platform content moderation.